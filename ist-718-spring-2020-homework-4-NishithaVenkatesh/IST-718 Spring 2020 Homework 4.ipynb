{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Willard Williamson <wewillia@syr.edu>\n",
    "- Faculty Assistant: Yash Pasar <yspasar@syr.edu>\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers from your classmates.  Short code snippets are allowed from the internet.  Code from the class text books or class provided code can be copied in its entirety.__\n",
    "- There could be tests in some cells (i.e., `assert` and `np.testing.` statements). These tests (if present) are used to grade your answers. **However, the professor and FAs could use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before submitting your work, remember to check for run time errors with the following procedure:\n",
    "`Kernel`$\\rightarrow$`Restart and Run All`.  All runtime errors will result in a minimum penalty of half off.\n",
    "- Data Bricks is the official class runtime environment so you should test your code on Data Bricks before submission.  If there is a runtime problem in the grading environment, we will try your code on Data Bricks before making a final grading decision.\n",
    "- All plots shall include a title, and axis labels.\n",
    "- Grading feedback cells are there for graders to provide feedback to students.  Don't change or remove grading feedback cells.\n",
    "- Don't add or remove files from your git repo.\n",
    "- Do not change file names in your repo.  This also means don't change the title of the ipython notebook.\n",
    "- You are free to add additional code cells around the cells marked `your code here`.\n",
    "- Students may use toPandas() to print the head of data frames.\n",
    "- __Only use spark, spark machine learning, spark data frames, RDD's, and map reduce to solve all problems unless instructed otherwise.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not delete or change this cell\n",
    "\n",
    "import os\n",
    "\n",
    "# Define a function to determine if we are running on data bricks\n",
    "# Return true if running in the data bricks environment, false otherwise\n",
    "def is_databricks():\n",
    "    # get the databricks runtime version\n",
    "    db_env = os.getenv(\"DATABRICKS_RUNTIME_VERSION\")\n",
    "    \n",
    "    # if running on data bricks\n",
    "    if db_env != None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Define a function to read the data file.  The full path data file name is constructed\n",
    "# by checking runtime environment variables to determine if the runtime environment is \n",
    "# databricks, or a student's personal computer.  The full path file name is then\n",
    "# constructed based on the runtime env.\n",
    "# \n",
    "# Params\n",
    "#   data_file_name: The base name of the data file to load\n",
    "# \n",
    "# Returns the full path file name based on the runtime env\n",
    "#\n",
    "def get_training_filename(data_file_name):    \n",
    "    # if running on data bricks\n",
    "    if is_databricks():\n",
    "        # build the full path file name assuming data brick env\n",
    "        full_path_name = \"/FileStore/tables/%s\" % data_file_name\n",
    "    # else the data is assumed to be in the same dir as this notebook\n",
    "    else:\n",
    "        # Assume the student is running on their own computer and load the data\n",
    "        # file from the same dir as this notebook\n",
    "        full_path_name = data_file_name\n",
    "    \n",
    "    # return the full path file name to the caller\n",
    "    return full_path_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Using the get_training_filename function defined in the cell above, read the sms_spam.csv file into a spark dataframe named spam_df.  There should be no empty columns in spam_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|type|                text|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam_df = spark.read.csv(get_training_filename('sms_spam.csv'), header = True, inferSchema = True)\n",
    "\n",
    "spam_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Starting with spam_df, create a new dataframe named spam_df1.  Rename the spam_df type column to be named spam.  In the spam column, replace the string `spam` the with the integer 1 and the string `ham` with the integer 0.  Print the head and shape of spam_df1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|spam|                text|\n",
      "+----+--------------------+\n",
      "|   0|Go until jurong p...|\n",
      "|   0|Ok lar... Joking ...|\n",
      "|   1|Free entry in 2 a...|\n",
      "|   0|U dun say so earl...|\n",
      "|   0|Nah I don't think...|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Shape of spam_df1: (5574, 2)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "spam_df1 = spam_df.withColumnRenamed(\"type\", \"spam\")\n",
    "spam_df1 = spam_df1.withColumn(\"spam\", when(spam_df1.spam == \"spam\", 1).otherwise(0))\n",
    "\n",
    "spam_df1.show(5)\n",
    "\n",
    "print(\"Shape of spam_df1:\", (spam_df1.count(), len(spam_df1.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Starting with spam_df1, create a new dataframe named spam_df2 with a new column named filtered_text by removing stop words from the text column in spam_df.  Print the head and shape of spam_df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+\n",
      "|spam|                text|               words|       filtered_text|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "|   0|Go until jurong p...|[go, until, juron...|[jurong, point,, ...|\n",
      "|   0|Ok lar... Joking ...|[ok, lar..., joki...|[ok, lar..., joki...|\n",
      "|   1|Free entry in 2 a...|[free, entry, in,...|[free, entry, 2, ...|\n",
      "|   0|U dun say so earl...|[u, dun, say, so,...|[u, dun, say, ear...|\n",
      "|   0|Nah I don't think...|[nah, i, don't, t...|[nah, don't, thin...|\n",
      "+----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Shape of spam_df2: (5574, 4)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "import requests\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "tokenizer = Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")\n",
    "stop_words = requests.get(\"http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words\").text.split()\n",
    "\n",
    "sw_filter = StopWordsRemover()\\\n",
    "  .setStopWords(stop_words)\\\n",
    "  .setCaseSensitive(False)\\\n",
    "  .setInputCol(\"words\")\\\n",
    "  .setOutputCol(\"filtered_text\")\n",
    "\n",
    "spam_df2 = Pipeline(stages = [tokenizer, sw_filter]).fit(spam_df1).transform(spam_df1)\n",
    "\n",
    "spam_df2.show(5)\n",
    "\n",
    "print(\"Shape of spam_df2:\", (spam_df2.count(), len(spam_df2.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "Create a new dataframe named spam_df3 starting with spam_df2.  Create a new column named tfidf by performing a term frequency / inverse document frequency transformation on the filtered_text column of spam_df2.<br>  \n",
    "\n",
    "- Print the head and shape of spam_df3.  \n",
    "- Print the top 10 most important words indicated by the TFIDF score.  \n",
    "- Print the 10 least important words as indicated by the TFIDF score.\n",
    "- Print the total number of columns in the TFIDF data in spam_df3\n",
    "- Print the number of rows in the TFIDF data in spam_df3\n",
    "- Based only on the number of rows and columns in the TFIDF data, do you expect the model to overfit.  Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|spam|                text|               words|       filtered_text|                  tf|               tfidf|\n",
      "+----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   0|Go until jurong p...|[go, until, juron...|[jurong, point,, ...|(1799,[10,29,56,6...|(1799,[10,29,56,6...|\n",
      "|   0|Ok lar... Joking ...|[ok, lar..., joki...|[ok, lar..., joki...|(1799,[0,23,268,4...|(1799,[0,23,268,4...|\n",
      "|   1|Free entry in 2 a...|[free, entry, in,...|[free, entry, 2, ...|(1799,[1,12,18,28...|(1799,[1,12,18,28...|\n",
      "|   0|U dun say so earl...|[u, dun, say, so,...|[u, dun, say, ear...|(1799,[0,64,71,11...|(1799,[0,64,71,11...|\n",
      "|   0|Nah I don't think...|[nah, i, don't, t...|[nah, don't, thin...|(1799,[30,35,279,...|(1799,[30,35,279,...|\n",
      "+----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Shape of spam_df3: (5574, 6)\n",
      "\n",
      "10 most important words: ['moan', 'eating', 'dear..', 'please.', 'directly', 'fantasy', 'jiu', 'also.', 'ym', 'reply...']\n",
      "\n",
      "10 least important words: ['u', '2', '', 'ur', \"i'm\", 'just', '&lt;#&gt;', '4', '.', 'like']\n",
      "\n",
      "Total number of columns in TFIDF: 1799\n",
      "\n",
      "Total number of rows in TFIDF: 1\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "cv = CountVectorizer(minTF = 1., minDF = 5., vocabSize = 2**17)\\\n",
    "  .setInputCol(\"filtered_text\")\\\n",
    "  .setOutputCol(\"tf\")\n",
    "\n",
    "idf = IDF()\\\n",
    "    .setInputCol(\"tf\")\\\n",
    "    .setOutputCol(\"tfidf\")\n",
    "\n",
    "cv_pipe = Pipeline(stages=[cv, idf]).fit(spam_df2)\n",
    "\n",
    "spam_df3 = cv_pipe.transform(spam_df2)\n",
    "    \n",
    "spam_df3.show(5)\n",
    "\n",
    "print(\"Shape of spam_df3:\", (spam_df3.count(), len(spam_df3.columns)))\n",
    "\n",
    "print(\"\\n10 most important words:\", cv_pipe.stages[0].vocabulary[-10: ])\n",
    "\n",
    "print(\"\\n10 least important words:\", cv_pipe.stages[0].vocabulary[0: 10])\n",
    "\n",
    "tfidf = spam_df3.select(col('tfidf')).collect()\n",
    "\n",
    "print(\"\\nTotal number of columns in TFIDF:\", len(tfidf[0][0]))\n",
    "\n",
    "print(\"\\nTotal number of rows in TFIDF:\", len(tfidf[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model overfit explanation here: \n",
    "\n",
    "There won't be any model overfitting problem as the number of features in the dataset is less than the total number of observations in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Create a pipeline named pipe1 capable of predicting ham or spam using logistic regression using spam_df3 as input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "train_df, test_df = spam_df3.randomSplit([0.6, 0.4], seed = 0)\n",
    "\n",
    "lr = LogisticRegression()\\\n",
    "    .setLabelCol(\"spam\")\\\n",
    "    .setFeaturesCol(\"tfidf\")\\\n",
    "    .setRegParam(0.0)\\\n",
    "    .setMaxIter(100)\\\n",
    "    .setElasticNetParam(0.)\n",
    "\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "pipe1 = Pipeline(stages = [lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "Fit pipe1 using a [CrossValidator](https://spark.apache.org/docs/2.2.0/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator) object with the number of cross validation folds = 3.  Score the model using a [BinaryClassificationEvaluator](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html) using ROC AUC as the metric.  Name the cross validator object cv1 and the fitted cross validator object fitted_cv1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "grid = ParamGridBuilder().build()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol = lr.getLabelCol(), rawPredictionCol = lr.getRawPredictionCol())\n",
    "\n",
    "cv1 = CrossValidator(estimator = pipe1, estimatorParamMaps = grid, evaluator = evaluator, numFolds = 3)\n",
    "\n",
    "fitted_cv1 = cv1.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "Print the cross validation AUC score from fitted_cv1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9438500203274579"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(fitted_cv1.transform(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "Create a ROC scatter plot from fitted_pipe1 TPR/FPR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (5, 5))\n",
    "plt.scatter(fitted_cv1.bestModel.stages[-1].summary.roc.select('FPR').collect(),\n",
    "            fitted_cv1.bestModel.stages[-1].summary.roc.select('TPR').collect())\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Scatter Plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "Create a new cross validator object named cv2 similar to cv1 but this time add a ParamGridBuilder.  Define a grid of elastic net regularization parameters. Fit cv2 and name the resulting fitted cross validator fitted_cv2.  The number of parameters in your grid should be limited such that it runs in a reasonable amount of time (around 5 to 10 minutes max).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.elasticNetParam, [0., 0.01, 0.1])\\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01, 0.001, 0.0001])\\\n",
    "    .build()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol = lr.getLabelCol(), rawPredictionCol = lr.getRawPredictionCol())\n",
    "\n",
    "cv2 = CrossValidator(estimator = pipe1, estimatorParamMaps = grid, evaluator = evaluator, numFolds = 3)\n",
    "\n",
    "fitted_cv2 = cv2.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9\n",
    "- Print the resulting AUC from fitted_cv2. \n",
    "- Print the best model's L1 and L2 regularization parameters\n",
    "- Analyze the L1 feature selection:\n",
    "    - Print the total number of features\n",
    "    - Print the number of features that L1 regularization eliminated\n",
    "    - If any features were eliminated, print a sample of 10 words that were eliminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of fitted_cv2: 0.9860588925064051 \n",
      "\n",
      "{Param(parent='LogisticRegression_9a33ddbb2dd1', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0, Param(parent='LogisticRegression_9a33ddbb2dd1', name='regParam', doc='regularization parameter (>= 0).'): 0.01}\n",
      "\n",
      "Total number of features: 1799\n",
      "\n",
      "Number of features eliminated by L1 regularization: 5\n",
      "\n",
      "Eliminated features:\n",
      "\n",
      "          word  weight\n",
      "1511      off.     0.0\n",
      "1533       ran     0.0\n",
      "1664     brand     0.0\n",
      "1746      yoga     0.0\n",
      "1760  handset?     0.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"AUC of fitted_cv2:\", evaluator.evaluate(fitted_cv2.transform(test_df)),\"\\n\")\n",
    "\n",
    "all_models = []\n",
    "for j in range(len(grid)):\n",
    "\n",
    "    model = pipe1.fit(train_df, grid[j])\n",
    "    all_models.append(model)\n",
    "    \n",
    "accuracies = [m\\\n",
    "    .transform(test_df)\\\n",
    "    .select(fn.avg(fn.expr(\"float(spam = prediction)\")).alias(\"accuracy\"))\\\n",
    "    .first()\\\n",
    "    .accuracy for m in all_models]\n",
    "\n",
    "best_model_idx = np.argmax(accuracies)\n",
    "print(grid[best_model_idx])\n",
    "\n",
    "en_weights = fitted_cv2.bestModel.stages[-1].coefficients.toArray() \n",
    "en_coeffs_df = pd.DataFrame({'word': cv_pipe.stages[0].vocabulary, 'weight': en_weights})\n",
    "\n",
    "print(\"\\nTotal number of features:\", len(en_weights))\n",
    "\n",
    "print(\"\\nNumber of features eliminated by L1 regularization:\", (en_weights == 0.0).sum())\n",
    "\n",
    "print(\"\\nEliminated features:\\n\")\n",
    "print(en_coeffs_df.query('weight == 0.0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10\n",
    "Analyze the best model weights in fitted_cv2.  Print the 10 words that contribute the most to predicting spam.  Print the 10 words that contribute the least to predicting spam.  Do the words make sense?  Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 words that contribute the most to predicting spam:\n",
      "\n",
      "          word    weight\n",
      "1535  welcome.  0.439890\n",
      "767    auction  0.431819\n",
      "1552      won!  0.379239\n",
      "643     apply.  0.343334\n",
      "1621   amazing  0.313968\n",
      "459     urgent  0.313275\n",
      "1045      link  0.313142\n",
      "514   message.  0.307855\n",
      "1601  content.  0.307647\n",
      "1275      msg:  0.305405\n",
      "\n",
      "10 words that contribute the least to predicting spam:\n",
      "\n",
      "               word    weight\n",
      "1369  fullonsms.com -0.110904\n",
      "1590         social -0.110574\n",
      "1357           list -0.110082\n",
      "1540           asks -0.103868\n",
      "494               s -0.087536\n",
      "1665         email. -0.082078\n",
      "1469          share -0.080825\n",
      "1749            cal -0.080211\n",
      "1708          some1 -0.080195\n",
      "1488           pete -0.076773\n"
     ]
    }
   ],
   "source": [
    "print(\"10 words that contribute the most to predicting spam:\\n\")\n",
    "print(en_coeffs_df.sort_values('weight', ascending = False).head(10))\n",
    "\n",
    "print(\"\\n10 words that contribute the least to predicting spam:\\n\")\n",
    "print(en_coeffs_df.sort_values('weight').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your comments here:\n",
    "\n",
    "- The words make sense as most of the spam SMS have words like 'won!', 'apply', 'amazing', which are part of the words that contribute the most to predicting spam.\n",
    "- Likewise, normal SMS has words like 'asks', 'email.', 'cal', which are part of the words that contribute the least to predicting spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra Credit (5 pts)**  This question is optional.  If you choose to answer this question, you will earn 5 extra credit points.  If you choose not to answer this question, no points will be deducted from your score.  Solve the following equation for $c$ symbolically using the python sympy package.  Convert the solved symbolic solution to a latex format (this can be done with a pyton call), then populate the solution cell with the resulting latex code so that your solution shows up symbolically similar the equation below.\n",
    "\n",
    "$$c g - c h + e \\left(a + 1\\right)^{b} - \\frac{d \\left(\\left(a + 1\\right)^{b} - 1\\right)}{a} + \\frac{f \\left(\\left(a + 1\\right)^{b} - 1\\right)}{a} = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not delete or change this cell\n",
    "\n",
    "# if running on data bricks\n",
    "if is_databricks():\n",
    "    # install sympy\n",
    "    dbutils.library.installPyPI\n",
    "    dbutils.library.installPyPI('sympy')\n",
    "    print(dbutils.library.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/latex": [
       "$\\displaystyle \\left[ \\frac{- a^{2} e e^{b} + a d e^{b} - a e e^{b} - a f e^{b} + d e^{b} - d - f e^{b} + f}{a \\left(g - h\\right)}\\right]$"
      ],
      "text/plain": [
       "⎡   2    b        b        b        b      b          b    ⎤\n",
       "⎢- a ⋅e⋅ℯ  + a⋅d⋅ℯ  - a⋅e⋅ℯ  - a⋅f⋅ℯ  + d⋅ℯ  - d - f⋅ℯ  + f⎥\n",
       "⎢──────────────────────────────────────────────────────────⎥\n",
       "⎣                        a⋅(g - h)                         ⎦"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import *\n",
    "from sympy.interactive import printing\n",
    "\n",
    "printing.init_printing(use_latex = True)\n",
    "\n",
    "a, b, c, d, e, f, g, h = symbols('a b c d e f g h')\n",
    "\n",
    "e = Eq((c * g) - (c * h) + e * (( a + 1) * exp(b)) - ((d * ((a + 1) * exp(b) - 1)) / a) + ((f * ((a + 1) * exp(b) -1)) / a))\n",
    "\n",
    "solve(e, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your latex output here such that a human readable equation is displayed for grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Feedback"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
