{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4e6cefb0049d48a2f4648d752841bb06",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Willard Williamson <wewillia@syr.edu>\n",
    "- Faculty Assistant: Palaniappan Muthukkaruppan\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers from your classmates.  Short code snippets are allowed from the internet.  Any code is allowed from the class text books or class provided code.__\n",
    "- Please do not change the file names. The FAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and FAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning: Use exclusively Spark 1.6 when asked to do so and Spark 2.0 (dataframes) only in the last question. Do not use Pandas at all in this assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data cleaning and basic analyses\n",
    "\n",
    "In this part, you will learn to read data from non-standard formats, clean data, and produce some basic analysis of it.\n",
    "\n",
    "We will use Spark 1.6 (`sparkContext` on variable `sc`) to load text files from which we will extract features that are predictive of a target value. Unfortunately, the data is stored in some non-standard format where each line contains the customer index, the feature index, and the value of the feature for that customer. Similarly, the target files contain in each line the customer index and the target value. We will load these files into two RDDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "52b18c5545e26c712a0ff9f85bf9e755",
     "grade": false,
     "grade_id": "cell-e8f7bc29c04e04e0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Adjust the following lines as needed to read the data files\n",
    "# If running on databricks, you will need to upload the data to databricks and then\n",
    "# adjust the file path as demonstrated in class.\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "db_env = os.getenv(\"DATABRICKS_RUNTIME_VERSION\")\n",
    "\n",
    "def get_training_filename(data_file_name):    \n",
    "    \n",
    "    grading_env = os.getenv(\"GRADING_RUNTIME_ENV\")\n",
    "    \n",
    "    if db_env != None:\n",
    "\n",
    "        full_path_name = \"/FileStore/tables/%s\" % data_file_name\n",
    "\n",
    "    elif grading_env != None:\n",
    "\n",
    "        full_path_name = \"%s/%s\" % (grading_env, data_file_name)\n",
    "\n",
    "    else:\n",
    "\n",
    "        full_path_name = data_file_name\n",
    "    \n",
    "\n",
    "    return full_path_name\n",
    "  \n",
    "raw_features_rdd = sc.textFile(get_training_filename('hw2_dataset_features.txt'))\n",
    "raw_target_rdd = sc.textFile(get_training_filename('hw2_dataset_targets.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An issue with the data is that there were problems transmitting the features and targets. If this happened, then a text `ERROR` or `ERROR TRANSFERRING` replaced the data. If you look at the first 10 values of the features and target RDD, you will see these types of lines:\n",
    "\n",
    "```python\n",
    "raw_features_rdd.take(10)\n",
    "```\n",
    "\n",
    "```\n",
    "['<customer_feature customer_id=0 feature_id=0>-0.57</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=1>-0.38</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=2>0.00</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=3>-0.07</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=4>-0.28</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=5>-0.79</customer_feature>',\n",
    " 'ERROR',\n",
    " '<customer_feature customer_id=0 feature_id=7>0.28</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=8>1.65</customer_feature>',\n",
    " '<customer_feature customer_id=0 feature_id=9>0.57</customer_feature>']\n",
    "```\n",
    "\n",
    "```python\n",
    "raw_target_rdd.take(35)\n",
    "```\n",
    "\n",
    "```\n",
    "['<customer_target customer_id=0>-252.49</customer_target>',\n",
    " '<customer_target customer_id=1>36.67</customer_target>',\n",
    " '<customer_target customer_id=2>138.02</customer_target>',\n",
    " '<customer_target customer_id=3>-429.54</customer_target>',\n",
    " '<customer_target customer_id=4>-18.23</customer_target>',\n",
    " '<customer_target customer_id=5>-5.52</customer_target>',\n",
    " '<customer_target customer_id=6>-31.96</customer_target>',\n",
    " 'ERROR TRANSFERRING',\n",
    " 'ERROR TRANSFERRING',\n",
    " '<customer_target customer_id=9>-111.88</customer_target>']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<customer_target customer_id=0>-252.49</customer_target>',\n",
       " '<customer_target customer_id=1>36.67</customer_target>',\n",
       " '<customer_target customer_id=2>138.02</customer_target>',\n",
       " '<customer_target customer_id=3>-429.54</customer_target>',\n",
       " '<customer_target customer_id=4>-18.23</customer_target>',\n",
       " '<customer_target customer_id=5>-5.52</customer_target>',\n",
       " '<customer_target customer_id=6>-31.96</customer_target>',\n",
       " 'ERROR TRANSFERRING',\n",
       " 'ERROR TRANSFERRING',\n",
       " '<customer_target customer_id=9>-111.88</customer_target>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it yourself: \n",
    "raw_features_rdd.take(10)\n",
    "raw_target_rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1 (10 pts):\n",
    "\n",
    "Filter out the lines that contain errors and store them in `raw_features2_rdd` and `raw_targets_rdd` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7258f0792387b2cdd0c4bb92886496ad",
     "grade": false,
     "grade_id": "cell-626aab3709c46ced",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create raw_features2_rdd and raw_targets2_rdd below\n",
    "raw_features2_rdd = raw_features_rdd.filter(lambda x: 'ERROR' not in x)\n",
    "\n",
    "raw_target2_rdd = raw_target_rdd.filter(lambda x: 'ERROR TRANSFERRING' not in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95036\n",
      "8968\n"
     ]
    }
   ],
   "source": [
    "# check that things work\n",
    "print(raw_features2_rdd.count())\n",
    "print(raw_target2_rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "34b858b2a4dae4c0c6569a235758d7e7",
     "grade": true,
     "grade_id": "cell-16fe9b731c74bdb1",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"10 pts: Check that the lines are properly discarded\"\"\"\n",
    "assert raw_features2_rdd.count() == 95036\n",
    "assert raw_target2_rdd.count() == 8968"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2 (10 pts):\n",
    "You will further process `raw_features2_rdd` such that you will create a key-value RDD of the following form: the key is the customer index as an integer and the value is a dictionary whose key is a string `f_0`, `f_1`, ..., `f_9` for feature index 0, 1, ... 9, respetively, and the value is a floating point number of the feature value. \n",
    "\n",
    "Define a function `map_features2` that performs such key-value pair creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1ac97b311e4bedac55e3aee7cf0a78b3",
     "grade": false,
     "grade_id": "cell-6a8bd9ba37f02ccc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def map_features2(line):\n",
    "    \n",
    "    x = line.split()\n",
    "    \n",
    "    return [int(x[1][12:]), {'f_'+x[2][11]: float(x[2][13:-19])}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for the input element:\n",
    "\n",
    "`'<customer_feature customer_id=4 feature_id=0>-0.79</customer_feature>'`\n",
    "\n",
    "it should generate\n",
    "```python\n",
    "[4, {'f_0': -0.79}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, {'f_0': -0.57}],\n",
       " [0, {'f_1': -0.38}],\n",
       " [0, {'f_2': 0.0}],\n",
       " [0, {'f_3': -0.07}],\n",
       " [0, {'f_4': -0.28}],\n",
       " [0, {'f_5': -0.79}],\n",
       " [0, {'f_7': 0.28}],\n",
       " [0, {'f_8': 1.65}],\n",
       " [0, {'f_9': 0.57}],\n",
       " [1, {'f_0': 0.5}]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it here\n",
    "raw_features2_rdd.\\\n",
    "    map(map_features2).\\\n",
    "    take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d152e2bbb8f36de1ff57cf05b404ff89",
     "grade": true,
     "grade_id": "cell-185fc07f367e8eb6",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"10 pts: Check that the new raw_features2_rdd and raw_target2_rdd RDDs are correct\"\"\"\n",
    "# key is an integer\n",
    "np.testing.assert_equal(type(raw_features2_rdd.map(map_features2).first()[0]), int)\n",
    "# value is a dictionary\n",
    "np.testing.assert_equal(type(raw_features2_rdd.map(map_features2).first()[1]), dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3 (5 pts):\n",
    "\n",
    "You will create a function `map_target2` that will be applied to `raw_target2_rdd`. This function will create key-value pair where the key is the customer index as an integer and the value is the floating point representation of the target. Assign the resulting RDD to `raw_target3_rdd`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "35c7e987523d093eba540b64dffb0e78",
     "grade": false,
     "grade_id": "cell-0a9dc80ecf0c1b6a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def map_target2(line):\n",
    "    \n",
    "    x = line.split()\n",
    "    y = x[1].split('>')\n",
    "    \n",
    "    return (int(y[0][12:]), float(y[1][0:-17]))\n",
    "\n",
    "# make the assignment here\n",
    "raw_target3_rdd = raw_target2_rdd.map(map_target2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample of results:\n",
    "\n",
    "```python\n",
    "raw_target2_rdd.map(map_target2).sortByKey().take(5)\n",
    "```\n",
    "\n",
    "```\n",
    "[(0, -252.49), (1, 36.67), (2, 138.02), (3, -429.54), (4, -18.23)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, -252.49), (1, 36.67), (2, 138.02), (3, -429.54), (4, -18.23)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try it yourself\n",
    "raw_target2_rdd.map(map_target2).sortByKey().take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3a9dcf95e4643d24fa6987f060f6b479",
     "grade": true,
     "grade_id": "cell-00147973f05ae1e7",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"5 pts: Check that raw_target3_rdd contains the right values\"\"\"\n",
    "# check types\n",
    "np.testing.assert_equal(type(raw_target3_rdd.keys().first()), int)\n",
    "np.testing.assert_equal(type(raw_target3_rdd.values().first()), float)\n",
    "# the sum of all targets\n",
    "np.testing.assert_approx_equal(raw_target3_rdd.values().sum(), -179351.71, significant=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.4 (10 pts):\n",
    "\n",
    "In this question, you will use map reduce to produce an RDD of key-value pairs where the key is the customer index and the value is a dictionairy with all the features and values associated with that customer. Notice that the map part of the map-reduce is already defined by `map_features2` on `raw_features2_rdd`. Therefore, define the proper `reduce_features2` function to produce the desired results. Create a RDD named `raw_features3_rdd` with the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bf88749fa6073bb62b123416b87783c6",
     "grade": false,
     "grade_id": "cell-c51c5ed026c36cb7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def reduce_features2(v1, v2):\n",
    "    \n",
    "    return {**v1, **v2}\n",
    "\n",
    "# Apply mapreduce to produce the raw_features3_rdd from raw_features2_rdd\n",
    "raw_features3_rdd = raw_features2_rdd.map(map_features2).reduceByKey(reduce_features2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the map reduce should produce the following example result:\n",
    "```python\n",
    "raw_features3_rdd.sortByKey().take(2)\n",
    "```\n",
    "\n",
    "```console\n",
    "[(0,\n",
    "  {'f_0': -0.57,\n",
    "   'f_1': -0.38,\n",
    "   'f_2': 0.0,\n",
    "   'f_3': -0.07,\n",
    "   'f_4': -0.28,\n",
    "   'f_5': -0.79,\n",
    "   'f_7': 0.28,\n",
    "   'f_8': 1.65,\n",
    "   'f_9': 0.57}),\n",
    " (1,\n",
    "  {'f_0': 0.5,\n",
    "   'f_1': 0.8,\n",
    "   'f_2': -0.49,\n",
    "   'f_3': 0.25,\n",
    "   'f_4': 0.37,\n",
    "   'f_5': 0.73,\n",
    "   'f_6': -0.43,\n",
    "   'f_7': 0.89,\n",
    "   'f_8': -1.85,\n",
    "   'f_9': -0.44})]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ed95bb2f5c17ad9f9fd2528d2a551730",
     "grade": true,
     "grade_id": "cell-f74bab4029291e96",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"10 pts: Check that raw_features3_rdd has the correct format and values. There could be hidden tests!\"\"\"\n",
    "# key is an integer\n",
    "np.testing.assert_equal(type(raw_features3_rdd.first()[0]), int)\n",
    "# value is a dictionary\n",
    "np.testing.assert_equal(type(raw_features3_rdd.first()[1]), dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.5 (20 pts):\n",
    "\n",
    "Join the two RDDs `raw_target3_rdd` and `raw_features3_rdd` to create an RDD with elements of the form\n",
    "\n",
    "`[customer_index, (target, feature_dict)]`\n",
    "\n",
    "where `target` comes from `raw_target3_rdd`, and `feature_dict` is the dictionary with features from `raw_features3_rdd`.\n",
    "\n",
    "Assign to `rdd_complete` a filtered version of the join for customers who have all 10 features and a target.\n",
    "\n",
    "Finally use `rdd_complete_rows` to create an RDD of `Row` objects where you map each entry to the following format:\n",
    "\n",
    "`Row(customer_index,  f_0,  f_1,  f_2,  f_3,  f_4,  f_5,  f_6,  f_7,  f_8,  f_9, target)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, from `rdd_complete`:\n",
    "\n",
    "```python\n",
    "rdd_complete.sortByKey().first()\n",
    "```\n",
    "should return\n",
    "```\n",
    "(1,\n",
    " (36.67,\n",
    "  {'f_0': 0.5,\n",
    "   'f_1': 0.8,\n",
    "   'f_2': -0.49,\n",
    "   'f_3': 0.25,\n",
    "   'f_4': 0.37,\n",
    "   'f_5': 0.73,\n",
    "   'f_6': -0.43,\n",
    "   'f_7': 0.89,\n",
    "   'f_8': -1.85,\n",
    "   'f_9': -0.44}))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "758a59186ed17064075d698f947a4784",
     "grade": false,
     "grade_id": "cell-225a18b6658c1598",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create rdd_complete here\n",
    "rdd_complete = raw_target3_rdd.join(raw_features3_rdd).filter(lambda x: (len(x[1][1]) == 10) and (x[1][0] != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "57ff1356246ff36cf7c81d5fe8b33b87",
     "grade": true,
     "grade_id": "cell-47b082a8f8d07296",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"10 pts: Test if `rdd1` has the right data. Remember that there could be hidden tests!\"\"\"\n",
    "# number of elements expected\n",
    "np.testing.assert_equal(rdd_complete.count(), 5379)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e518b98058f857ef947f11afe2774230",
     "grade": false,
     "grade_id": "cell-63a9f734c2e8d9f1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# here define the function to_row that a Row object for an entry of rdd_complete\n",
    "def to_row(e):\n",
    "    \n",
    "    return Row(customer_index = e[0], \n",
    "               f_0 = e[1][1].get('f_0'), \n",
    "               f_1 = e[1][1].get('f_1'), \n",
    "               f_2 = e[1][1].get('f_2'), \n",
    "               f_3 = e[1][1].get('f_3'), \n",
    "               f_4 = e[1][1].get('f_4'), \n",
    "               f_5 = e[1][1].get('f_5'), \n",
    "               f_6 = e[1][1].get('f_6'), \n",
    "               f_7 = e[1][1].get('f_7'), \n",
    "               f_8 = e[1][1].get('f_8'), \n",
    "               f_9 = e[1][1].get('f_9'), \n",
    "               target = e[1][0])\n",
    "\n",
    "complete_df = rdd_complete.map(to_row).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|customer_index|  f_0|  f_1|  f_2|  f_3|  f_4|  f_5|  f_6|  f_7|  f_8|  f_9| target|\n",
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|             1|  0.5|  0.8|-0.49| 0.25| 0.37| 0.73|-0.43| 0.89|-1.85|-0.44|  36.67|\n",
      "|             3| 0.14|-0.87|-0.94| 0.09|-0.69|-0.29|-0.45| -0.6|-1.28|-0.38|-429.54|\n",
      "|             4|-0.79|-0.28|-0.26| 0.28|-0.17|-0.51| 0.44|-0.62| 1.82|-0.35| -18.23|\n",
      "|             5|-0.11| 0.86| -1.3|-0.09|-0.12|-0.47| 0.05| 0.98|-1.59|  0.3|  -5.52|\n",
      "|             9| 0.57| 0.07|-0.31|-0.92|-0.26| -0.9|-0.06|-0.76| 1.39| 0.01|-111.88|\n",
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "rdd_complete.map(to_row).toDF().orderBy('customer_index').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2d8a63ee5a5324c0b86e37742630d9b7",
     "grade": true,
     "grade_id": "cell-a1f30aae3cf357e3",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts test that the creation of the row is successful\n",
    "assert rdd_complete.map(to_row).toDF()\n",
    "np.testing.assert_array_equal(rdd_complete.map(to_row).toDF().columns, \n",
    "              ['customer_index',\n",
    " 'f_0',\n",
    " 'f_1',\n",
    " 'f_2',\n",
    " 'f_3',\n",
    " 'f_4',\n",
    " 'f_5',\n",
    " 'f_6',\n",
    " 'f_7',\n",
    " 'f_8',\n",
    " 'f_9',\n",
    " 'target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.6 (20 pts):\n",
    "\n",
    "We will now use the `to_row` function created above to create a dataframe of the data `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e32c44443a35936770c76a2af3848e70",
     "grade": false,
     "grade_id": "cell-e81ad00df6011794",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = rdd_complete.map(to_row).toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the dataframe a bit:\n",
    "\n",
    "```python\n",
    "df.orderBy('customer_index').show(5)\n",
    "```\n",
    "\n",
    "```console\n",
    "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
    "|customer_index|  f_0|  f_1|  f_2|  f_3|  f_4|  f_5|  f_6|  f_7|  f_8|  f_9| target|\n",
    "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
    "|             1|  0.5|  0.8|-0.49| 0.25| 0.37| 0.73|-0.43| 0.89|-1.85|-0.44|  36.67|\n",
    "|             3| 0.14|-0.87|-0.94| 0.09|-0.69|-0.29|-0.45| -0.6|-1.28|-0.38|-429.54|\n",
    "|             4|-0.79|-0.28|-0.26| 0.28|-0.17|-0.51| 0.44|-0.62| 1.82|-0.35| -18.23|\n",
    "|             5|-0.11| 0.86| -1.3|-0.09|-0.12|-0.47| 0.05| 0.98|-1.59|  0.3|  -5.52|\n",
    "|             9| 0.57| 0.07|-0.31|-0.92|-0.26| -0.9|-0.06|-0.76| 1.39| 0.01|-111.88|\n",
    "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
    "only showing top 5 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|customer_index|  f_0|  f_1|  f_2|  f_3|  f_4|  f_5|  f_6|  f_7|  f_8|  f_9| target|\n",
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "|             1|  0.5|  0.8|-0.49| 0.25| 0.37| 0.73|-0.43| 0.89|-1.85|-0.44|  36.67|\n",
      "|             3| 0.14|-0.87|-0.94| 0.09|-0.69|-0.29|-0.45| -0.6|-1.28|-0.38|-429.54|\n",
      "|             4|-0.79|-0.28|-0.26| 0.28|-0.17|-0.51| 0.44|-0.62| 1.82|-0.35| -18.23|\n",
      "|             5|-0.11| 0.86| -1.3|-0.09|-0.12|-0.47| 0.05| 0.98|-1.59|  0.3|  -5.52|\n",
      "|             9| 0.57| 0.07|-0.31|-0.92|-0.26| -0.9|-0.06|-0.76| 1.39| 0.01|-111.88|\n",
      "+--------------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explore it yourself\n",
    "df.orderBy('customer_index').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subpackage `pyspark.ml.functions` (aliased as `fn` below) contains many common functions for data analysis. Find the function for computing the __correlation__ (the strength of the linear relationship between two variables) between two columns, the function for computing __absolute__ values, and create a data frame `correlations_df` that contains the following columns in the following order:\n",
    "\n",
    "1. `c0_target`: correlation between feature 0 and target\n",
    "1. `c1_target`: correlation between feature 1 and target\n",
    "1. `c2_target`: correlation between feature 2 and target\n",
    "1. `c3_target`: correlation between feature 3 and target\n",
    "1. `c4_target`: correlation between feature 4 and target\n",
    "1. `c5_target`: correlation between feature 5 and target\n",
    "1. `c6_target`: correlation between feature 6 and target\n",
    "1. `c7_target`: correlation between feature 7 and target\n",
    "1. `c8_target`: correlation between feature 8 and target\n",
    "1. `c9_target`: correlation between feature 9 and target\n",
    "1. `sig0`: boolean `true` if the absolute value of the correlation between feature 0 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig1`: boolean `true` if the absolute value of the correlation between feature 1 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig2`: boolean `true` if the absolute value of the correlation between feature 2 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig3`: boolean `true` if the absolute value of the correlation between feature 3 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig4`: boolean `true` if the absolute value of the correlation between feature 4 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig5`: boolean `true` if the absolute value of the correlation between feature 5 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig6`: boolean `true` if the absolute value of the correlation between feature 6 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig7`: boolean `true` if the absolute value of the correlation between feature 7 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig8`: boolean `true` if the absolute value of the correlation between feature 8 and target is greater than 0.5, `false` o.w.\n",
    "1. `sig9`: boolean `true` if the absolute value of the correlation between feature 9 and target is greater than 0.5, `false` o.w.\n",
    "\n",
    "**Hint: Remember that you can pass a list of columns to `df.select`. You can create such list with list comprehension, saving a lot of code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the package functions as fn\n",
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply some function to the columns: df.select(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d50d7ffa26caed36ab9594774d715b63",
     "grade": false,
     "grade_id": "cell-12e8f5f6de39ae69",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create the dataframe `correlations_df` here\n",
    "correlations_df = df.select([fn.corr('f_' + str(i), 'target').alias('c' + str(i) +'_target')  for i in range(10)] + \n",
    "                            [(fn.abs(fn.corr('f_' + str(i), 'target')) > 0.5).alias('sig' + str(i)) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "86a41f3db733560238662ea32ca87d16",
     "grade": true,
     "grade_id": "cell-ea3814c44cba8dcc",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"20 pts: Check that the dataframe has the correct columns and values. There could be hidden tests!\"\"\"\n",
    "# check column names\n",
    "column_names = ['c' + str(fi) + '_target' for fi in range(10)] + \\\n",
    "               ['sig' + str(fi) for fi in range(10)]\n",
    "\n",
    "# column's names and positions in the right order\n",
    "np.testing.assert_equal(correlations_df.columns, column_names)\n",
    "\n",
    "from pyspark.sql.types import DoubleType, BooleanType\n",
    "\n",
    "\n",
    "# the types are correct\n",
    "np.testing.assert_equal([type(f.dataType) for f in correlations_df.schema.fields], \n",
    "                        10*[DoubleType] + 10*[BooleanType])\n",
    "\n",
    "# the values are correct\n",
    "np.testing.assert_approx_equal(correlations_df.toPandas().sum().sum(), \n",
    "                               4.963039476979365,\n",
    "                               significant=1)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
